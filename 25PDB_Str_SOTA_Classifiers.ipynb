{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('CE_Str_25PDB.csv')\n",
    "labels = data1['Class'].values\n",
    "feat_w2v = data1.drop(['PDBid', 'Class', 'Unnamed: 0'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 400)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7352941176470589, 0.6804733727810651, 0.7041420118343196, 0.7245508982035929, 0.6586826347305389, 0.7305389221556886, 0.6626506024096386, 0.6927710843373494, 0.6746987951807228, 0.6867469879518072]\n",
      "\n",
      "Accuracy NB CF:  0.6950549427231781\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_gnb = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    gnb.fit(X_train, Y_train)\n",
    "    pred = gnb.predict(X_test)\n",
    "    acc_gnb.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_gnb\n",
    "print '\\nAccuracy NB CF: ', np.mean(acc_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7705882352941177, 0.7455621301775148, 0.727810650887574, 0.7724550898203593, 0.7425149700598802, 0.7604790419161677, 0.6746987951807228, 0.7349397590361446, 0.7349397590361446, 0.7349397590361446]\n",
      "\n",
      "Accuracy SVM CF:  0.7398928190444771\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "a = SVC(kernel='rbf', C=4)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    a.fit(X_train, Y_train)\n",
    "    pred = a.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy SVM CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.6705882352941176, 0.6153846153846154, 0.6449704142011834, 0.6526946107784432, 0.6407185628742516, 0.6467065868263473, 0.6265060240963856, 0.6144578313253012, 0.608433734939759, 0.6506024096385542]\n",
      "\n",
      "Accuracy LogisticRegression CF:  0.6371063025358958\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "svm = LogisticRegression()\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy LogisticRegression CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7529411764705882, 0.7396449704142012, 0.7159763313609467, 0.7544910179640718, 0.7365269461077845, 0.7485029940119761, 0.6686746987951807, 0.7228915662650602, 0.7289156626506024, 0.7228915662650602]\n",
      "\n",
      "Accuracy Gradient Boosting CF:  0.7291456930305473\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.01, max_depth=3)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_gb = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    gb.fit(X_train, Y_train)\n",
    "    pred = gb.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_gb.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_gb   \n",
    "print '\\nAccuracy Gradient Boosting CF: ', np.mean(acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7470588235294118, 0.7396449704142012, 0.6804733727810651, 0.7005988023952096, 0.7365269461077845, 0.7485029940119761, 0.6807228915662651, 0.7409638554216867, 0.7168674698795181, 0.7168674698795181]\n",
      "\n",
      "Accuracy MLP CF:  0.7208227595986636\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(200, 5), max_iter=1000000, learning_rate='adaptive')\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_mlp = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_mlp.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_mlp   \n",
    "print '\\nAccuracy MLP CF: ', np.mean(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.6529411764705882, 0.6804733727810651, 0.6568047337278107, 0.7065868263473054, 0.6706586826347305, 0.6766467065868264, 0.6325301204819277, 0.7289156626506024, 0.7108433734939759, 0.6867469879518072]\n",
      "\n",
      "Accuracy KNN CF:  0.6803147643126639\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_knn = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    knn.fit(X_train, Y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_knn.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_knn    \n",
    "print '\\nAccuracy KNN CF: ', np.mean(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.91      0.92        46\n",
      "          1       0.76      0.77      0.76        44\n",
      "          2       0.63      0.56      0.59        39\n",
      "          3       0.53      0.59      0.56        41\n",
      "\n",
      "avg / total       0.72      0.72      0.72       170\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        42\n",
      "          1       0.73      0.85      0.79        39\n",
      "          2       0.69      0.55      0.61        44\n",
      "          3       0.55      0.55      0.55        44\n",
      "\n",
      "avg / total       0.69      0.70      0.69       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.82      0.85        49\n",
      "          1       0.80      0.77      0.78        47\n",
      "          2       0.40      0.52      0.45        27\n",
      "          3       0.52      0.50      0.51        46\n",
      "\n",
      "avg / total       0.69      0.67      0.68       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.89      0.91        46\n",
      "          1       0.68      0.88      0.77        34\n",
      "          2       0.57      0.51      0.54        39\n",
      "          3       0.55      0.50      0.52        48\n",
      "\n",
      "avg / total       0.69      0.69      0.68       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85        41\n",
      "          1       0.84      0.79      0.81        47\n",
      "          2       0.46      0.50      0.48        32\n",
      "          3       0.61      0.57      0.59        47\n",
      "\n",
      "avg / total       0.70      0.69      0.70       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.84        47\n",
      "          1       0.75      0.73      0.74        45\n",
      "          2       0.37      0.57      0.45        23\n",
      "          3       0.55      0.46      0.50        52\n",
      "\n",
      "avg / total       0.67      0.65      0.65       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.95      0.89        39\n",
      "          1       0.64      0.82      0.72        34\n",
      "          2       0.59      0.43      0.50        46\n",
      "          3       0.50      0.47      0.48        47\n",
      "\n",
      "avg / total       0.63      0.64      0.63       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.82      0.83        45\n",
      "          1       0.77      0.87      0.82        39\n",
      "          2       0.62      0.60      0.61        35\n",
      "          3       0.57      0.53      0.55        47\n",
      "\n",
      "avg / total       0.70      0.70      0.70       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.81      0.85        48\n",
      "          1       0.77      0.74      0.76        46\n",
      "          2       0.56      0.54      0.55        35\n",
      "          3       0.48      0.57      0.52        37\n",
      "\n",
      "avg / total       0.69      0.68      0.69       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84        42\n",
      "          1       0.73      0.80      0.76        40\n",
      "          2       0.44      0.48      0.46        31\n",
      "          3       0.55      0.45      0.49        53\n",
      "\n",
      "avg / total       0.64      0.64      0.64       166\n",
      "\n",
      "\n",
      "Fold Accuracies:  [0.7176470588235294, 0.6982248520710059, 0.6686390532544378, 0.688622754491018, 0.6946107784431138, 0.6467065868263473, 0.6445783132530121, 0.7048192771084337, 0.6807228915662651, 0.6445783132530121]\n",
      "\n",
      "Accuracy RF CF:  0.6789149879090175\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=360)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_rf = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    rf.fit(X_train, Y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    #print confusion_matrix(pred, Y_test)\n",
    "    print classification_report(pred, Y_test)\n",
    "    acc_rf.append(accuracy_score(pred, Y_test))\n",
    "    #conf_rf.append(classification_report(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_rf    \n",
    "print '\\nAccuracy RF CF: ', np.mean(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

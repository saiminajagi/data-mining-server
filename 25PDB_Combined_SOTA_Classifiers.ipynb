{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined\n",
    "import pandas as pd\n",
    "data1 = pd.read_csv('CE_Seq_25PDB.csv')\n",
    "data2 = pd.read_csv('CE_Str_25PDB.csv')\n",
    "\n",
    "features1 = data1.drop(['Unnamed: 0'], axis=1)\n",
    "features2 = data2.drop(['Unnamed: 0', 'Class'], axis=1)\n",
    "features12 = features1.merge(features2, on=['PDBid'], how='inner')\n",
    "\n",
    "labels = features12['Class'].values\n",
    "feat_w2v = features12.drop(['PDBid', 'Class'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 800)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7529411764705882, 0.6804733727810651, 0.7159763313609467, 0.7065868263473054, 0.688622754491018, 0.7305389221556886, 0.7048192771084337, 0.6927710843373494, 0.7168674698795181, 0.6867469879518072]\n",
      "\n",
      "Accuracy NB CF:  0.707634420288372\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_gnb = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    gnb.fit(X_train, Y_train)\n",
    "    pred = gnb.predict(X_test)\n",
    "    acc_gnb.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_gnb\n",
    "print '\\nAccuracy NB CF: ', np.mean(acc_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7647058823529411, 0.7692307692307693, 0.7810650887573964, 0.7844311377245509, 0.718562874251497, 0.7425149700598802, 0.6987951807228916, 0.7469879518072289, 0.7168674698795181, 0.7289156626506024]\n",
      "\n",
      "Accuracy SVM CF:  0.7452076987437276\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "a = SVC(kernel='rbf', C=4)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    a.fit(X_train, Y_train)\n",
    "    pred = a.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy SVM CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7058823529411765, 0.6863905325443787, 0.7041420118343196, 0.718562874251497, 0.688622754491018, 0.7125748502994012, 0.7048192771084337, 0.6927710843373494, 0.6746987951807228, 0.6746987951807228]\n",
      "\n",
      "Accuracy LogisticRegression CF:  0.6963163328169019\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "svm = LogisticRegression()\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy LogisticRegression CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7764705882352941, 0.7514792899408284, 0.7041420118343196, 0.7664670658682635, 0.7305389221556886, 0.7904191616766467, 0.6867469879518072, 0.7409638554216867, 0.7409638554216867, 0.7289156626506024]\n",
      "\n",
      "Accuracy Gradient Boosting CF:  0.7417107401156825\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.01, max_depth=3)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_gb = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    gb.fit(X_train, Y_train)\n",
    "    pred = gb.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_gb.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_gb   \n",
    "print '\\nAccuracy Gradient Boosting CF: ', np.mean(acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.7, 0.7396449704142012, 0.6094674556213018, 0.6706586826347305, 0.6407185628742516, 0.6287425149700598, 0.6506024096385542, 0.6626506024096386, 0.6686746987951807, 0.6506024096385542]\n",
      "\n",
      "Accuracy MLP CF:  0.6621762306996473\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(200, 5), max_iter=1000000, learning_rate='adaptive')\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_mlp = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_mlp.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_mlp   \n",
    "print '\\nAccuracy MLP CF: ', np.mean(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.711764705882353, 0.6153846153846154, 0.7218934911242604, 0.7245508982035929, 0.6946107784431138, 0.7305389221556886, 0.6807228915662651, 0.6867469879518072, 0.6746987951807228, 0.6024096385542169]\n",
      "\n",
      "Accuracy KNN CF:  0.6843321724446636\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_knn = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    knn.fit(X_train, Y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_knn.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_knn    \n",
    "print '\\nAccuracy KNN CF: ', np.mean(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95        43\n",
      "          1       0.76      0.89      0.82        38\n",
      "          2       0.63      0.63      0.63        35\n",
      "          3       0.69      0.57      0.63        54\n",
      "\n",
      "avg / total       0.75      0.76      0.75       170\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.90      0.85        40\n",
      "          1       0.78      0.97      0.86        36\n",
      "          2       0.74      0.63      0.68        41\n",
      "          3       0.66      0.56      0.60        52\n",
      "\n",
      "avg / total       0.74      0.75      0.74       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.85      0.88        48\n",
      "          1       0.80      0.84      0.82        43\n",
      "          2       0.63      0.76      0.69        29\n",
      "          3       0.66      0.59      0.62        49\n",
      "\n",
      "avg / total       0.76      0.76      0.76       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93        46\n",
      "          1       0.70      0.82      0.76        38\n",
      "          2       0.60      0.70      0.65        30\n",
      "          3       0.68      0.57      0.62        53\n",
      "\n",
      "avg / total       0.75      0.74      0.74       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85        45\n",
      "          1       0.80      0.90      0.84        39\n",
      "          2       0.60      0.72      0.66        29\n",
      "          3       0.70      0.57      0.63        54\n",
      "\n",
      "avg / total       0.75      0.75      0.75       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91        42\n",
      "          1       0.77      0.83      0.80        41\n",
      "          2       0.83      0.72      0.77        40\n",
      "          3       0.61      0.61      0.61        44\n",
      "\n",
      "avg / total       0.77      0.77      0.77       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87        43\n",
      "          1       0.66      0.85      0.74        34\n",
      "          2       0.65      0.65      0.65        34\n",
      "          3       0.64      0.51      0.57        55\n",
      "\n",
      "avg / total       0.70      0.70      0.70       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88        45\n",
      "          1       0.77      0.94      0.85        36\n",
      "          2       0.68      0.68      0.68        34\n",
      "          3       0.73      0.63      0.67        51\n",
      "\n",
      "avg / total       0.77      0.77      0.77       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.90        49\n",
      "          1       0.73      0.84      0.78        38\n",
      "          2       0.68      0.72      0.70        32\n",
      "          3       0.64      0.60      0.62        47\n",
      "\n",
      "avg / total       0.76      0.75      0.75       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91        42\n",
      "          1       0.68      0.86      0.76        35\n",
      "          2       0.53      0.75      0.62        24\n",
      "          3       0.77      0.52      0.62        65\n",
      "\n",
      "avg / total       0.75      0.73      0.72       166\n",
      "\n",
      "\n",
      "Fold Accuracies:  [0.7588235294117647, 0.7455621301775148, 0.757396449704142, 0.7425149700598802, 0.7485029940119761, 0.7724550898203593, 0.7048192771084337, 0.7710843373493976, 0.7530120481927711, 0.7289156626506024]\n",
      "\n",
      "Accuracy RF CF:  0.7483086488486843\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=360)\n",
    "from sklearn.model_selection import KFold\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_rf = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    rf.fit(X_train, Y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    #print confusion_matrix(pred, Y_test)\n",
    "    print classification_report(pred, Y_test)\n",
    "    acc_rf.append(accuracy_score(pred, Y_test))\n",
    "    #conf_rf.append(classification_report(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_rf    \n",
    "print '\\nAccuracy RF CF: ', np.mean(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

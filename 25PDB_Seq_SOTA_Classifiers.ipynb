{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv('CE_Seq_25PDB.csv')\n",
    "labels = data1['Class'].values\n",
    "feat_w2v = data1.drop(['PDBid', 'Class', 'Unnamed: 0'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 400)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.45294117647058824, 0.4378698224852071, 0.44970414201183434, 0.49101796407185627, 0.5029940119760479, 0.4431137724550898, 0.41566265060240964, 0.46987951807228917, 0.4759036144578313, 0.3855421686746988]\n",
      "\n",
      "Accuracy NB CF:  0.45246288412778524\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_gnb = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    gnb.fit(X_train, Y_train)\n",
    "    pred = gnb.predict(X_test)\n",
    "    acc_gnb.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_gnb\n",
    "print '\\nAccuracy NB CF: ', np.mean(acc_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.5823529411764706, 0.5325443786982249, 0.5029585798816568, 0.49700598802395207, 0.49101796407185627, 0.4431137724550898, 0.4939759036144578, 0.5662650602409639, 0.5180722891566265, 0.46987951807228917]\n",
      "\n",
      "Accuracy SVM CF:  0.5097186395391589\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "a = SVC(kernel='rbf', C=4)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    a.fit(X_train, Y_train)\n",
    "    pred = a.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy SVM CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.5705882352941176, 0.5029585798816568, 0.4911242603550296, 0.5149700598802395, 0.5389221556886228, 0.5149700598802395, 0.5, 0.5120481927710844, 0.5, 0.4879518072289157]\n",
      "\n",
      "Accuracy LogisticRegression CF:  0.5133533350979905\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "svm = LogisticRegression()\n",
    "acc_svm = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    \n",
    "    svm.fit(X_train, Y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    acc_svm.append(accuracy_score(pred, Y_test))\n",
    "\n",
    "print '\\nFold Accuracies: ', acc_svm\n",
    "print '\\nAccuracy LogisticRegression CF: ', np.mean(acc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.47058823529411764, 0.4378698224852071, 0.48520710059171596, 0.5269461077844312, 0.5089820359281437, 0.5029940119760479, 0.4939759036144578, 0.5421686746987951, 0.5421686746987951, 0.45180722891566266]\n",
      "\n",
      "Accuracy Gradient Boosting CF:  0.49627077959873744\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(learning_rate=0.01, max_depth=3)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_gb = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    gb.fit(X_train, Y_train)\n",
    "    pred = gb.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_gb.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_gb   \n",
    "print '\\nAccuracy Gradient Boosting CF: ', np.mean(acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.45294117647058824, 0.3727810650887574, 0.42011834319526625, 0.38323353293413176, 0.4251497005988024, 0.41916167664670656, 0.3795180722891566, 0.41566265060240964, 0.40963855421686746, 0.40963855421686746]\n",
      "\n",
      "Accuracy MLP CF:  0.40878433262595537\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 3), max_iter=1000, learning_rate='adaptive')\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_mlp = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    pred = mlp.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_mlp.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_mlp   \n",
    "print '\\nAccuracy MLP CF: ', np.mean(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Accuracies:  [0.4764705882352941, 0.378698224852071, 0.38461538461538464, 0.3473053892215569, 0.49101796407185627, 0.41317365269461076, 0.43373493975903615, 0.41566265060240964, 0.463855421686747, 0.3493975903614458]\n",
      "\n",
      "Accuracy KNN CF:  0.4153931806100412\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_knn = []\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    knn = KNeighborsClassifier(n_neighbors=4)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    pred = knn.predict(X_test)\n",
    "#    print confusion_matrix(pred, Y_test)\n",
    "#   print classification_report(pred, Y_test)\n",
    "    acc_knn.append(accuracy_score(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_knn    \n",
    "print '\\nAccuracy KNN CF: ', np.mean(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.63      0.66        49\n",
      "          1       0.71      0.62      0.66        52\n",
      "          2       0.57      0.56      0.56        36\n",
      "          3       0.29      0.39      0.33        33\n",
      "\n",
      "avg / total       0.59      0.56      0.58       170\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.70        47\n",
      "          1       0.51      0.46      0.48        50\n",
      "          2       0.49      0.65      0.56        26\n",
      "          3       0.34      0.33      0.33        46\n",
      "\n",
      "avg / total       0.52      0.51      0.51       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.57      0.60        51\n",
      "          1       0.53      0.53      0.53        45\n",
      "          2       0.60      0.57      0.58        37\n",
      "          3       0.23      0.28      0.25        36\n",
      "\n",
      "avg / total       0.52      0.50      0.51       169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.70        45\n",
      "          1       0.59      0.54      0.57        48\n",
      "          2       0.46      0.43      0.44        37\n",
      "          3       0.32      0.38      0.35        37\n",
      "\n",
      "avg / total       0.53      0.52      0.53       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.57      0.63        54\n",
      "          1       0.55      0.53      0.54        45\n",
      "          2       0.46      0.57      0.51        28\n",
      "          3       0.34      0.38      0.36        40\n",
      "\n",
      "avg / total       0.53      0.51      0.52       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.59      0.54        37\n",
      "          1       0.59      0.52      0.55        50\n",
      "          2       0.54      0.47      0.51        40\n",
      "          3       0.27      0.30      0.29        40\n",
      "\n",
      "avg / total       0.48      0.47      0.48       167\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.55      0.60        53\n",
      "          1       0.48      0.48      0.48        44\n",
      "          2       0.41      0.44      0.42        32\n",
      "          3       0.32      0.38      0.35        37\n",
      "\n",
      "avg / total       0.49      0.47      0.48       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.61      0.65        51\n",
      "          1       0.68      0.61      0.65        49\n",
      "          2       0.47      0.53      0.50        30\n",
      "          3       0.30      0.36      0.33        36\n",
      "\n",
      "avg / total       0.57      0.54      0.55       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.68      0.70        47\n",
      "          1       0.64      0.54      0.58        52\n",
      "          2       0.50      0.42      0.46        40\n",
      "          3       0.23      0.37      0.28        27\n",
      "\n",
      "avg / total       0.56      0.52      0.54       166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.54      0.56        46\n",
      "          1       0.52      0.48      0.50        48\n",
      "          2       0.50      0.53      0.52        32\n",
      "          3       0.18      0.20      0.19        40\n",
      "\n",
      "avg / total       0.45      0.44      0.44       166\n",
      "\n",
      "\n",
      "Fold Accuracies:  [0.5647058823529412, 0.514792899408284, 0.4970414201183432, 0.5209580838323353, 0.5149700598802395, 0.47305389221556887, 0.46987951807228917, 0.5421686746987951, 0.5240963855421686, 0.4397590361445783]\n",
      "\n",
      "Accuracy RF CF:  0.5061425852265544\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=360)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "acc_rf = []\n",
    "\n",
    "for train, test in kf.split(feat_w2v, labels):\n",
    "    X_train, X_test = feat_w2v[train], feat_w2v[test]\n",
    "    Y_train, Y_test = labels[train], labels[test]\n",
    "    rf.fit(X_train, Y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    #print confusion_matrix(pred, Y_test)\n",
    "    print classification_report(pred, Y_test)\n",
    "    acc_rf.append(accuracy_score(pred, Y_test))\n",
    "    #conf_rf.append(classification_report(pred, Y_test))\n",
    "print '\\nFold Accuracies: ', acc_rf    \n",
    "print '\\nAccuracy RF CF: ', np.mean(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
